{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the findspark module \n",
    "import findspark\n",
    "\n",
    "# Initialize via the full spark path\n",
    "findspark.init(\"/usr/local/spark/\")\n",
    "#findspark.init(\"C:/spark/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SparkSession module\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import the collections module\n",
    "import collections\n",
    "\n",
    "# Gets an existing :class:`SparkSession` or, if there is no existing one, creates a\n",
    "# new one based on the options set in this builder.\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local[8]\") \\\n",
    "   .appName(\"RatingsHistogram\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "# Main entry point for Spark functionality. A SparkContext represents the\n",
    "# connection to a Spark cluster, and can be used to create :class:`RDD` and\n",
    "# broadcast variables on that cluster.\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb = sc.textFile(\"data/airbnb.csv\", minPartitions=4)\n",
    "\n",
    "\n",
    "header = airbnb.first()\n",
    "airbnb = airbnb.filter(lambda row: row != header)\n",
    "airbnb.take(15)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
